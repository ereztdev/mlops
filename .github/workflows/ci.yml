name: CI Pipeline

# This workflow runs on every push to main branch and on pull requests
on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  # Job 1: Lint and Test
  # This job validates code quality and runs tests
  lint-and-test:
    name: Lint and Test
    runs-on: ubuntu-latest
    
    steps:
    # Checkout the code from the repository
    - name: Checkout code
      uses: actions/checkout@v4
    
    # Set up Python environment
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.10'
    
    # Cache pip dependencies for faster builds
    - name: Cache pip packages
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    # Install dependencies
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    # Run code linting with flake8
    # This checks for code style and potential errors
    - name: Run linting (flake8)
      run: |
        flake8 src/ tests/ --count --select=E9,F63,F7,F82 --show-source --statistics
        flake8 src/ tests/ --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics
    
    # Run tests with pytest
    # This validates that all functionality works correctly
    - name: Run tests
      run: |
        pytest tests/ -v --cov=src --cov-report=term-missing
    
    # Optional: Run type checking with mypy
    # Uncomment if you want strict type checking
    # - name: Run type checking (mypy)
    #   run: |
    #     mypy src/ --ignore-missing-imports

  # Job 2: Training
  # This job trains the model to ensure training pipeline works
  train-model:
    name: Train Model
    runs-on: ubuntu-latest
    
    steps:
    # Checkout the code
    - name: Checkout code
      uses: actions/checkout@v4
    
    # Set up Python environment
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.10'
    
    # Cache pip dependencies
    - name: Cache pip packages
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    # Install dependencies
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    # Run training script
    # This ensures the training pipeline works and produces model artifacts
    - name: Train model
      run: |
        python src/training/train.py
    
    # Upload model artifacts, metrics, and MLflow tracking data
    # This saves the trained model files, metrics, and experiment history
    # Artifacts are stored for 7 days
    - name: Upload model artifacts
      uses: actions/upload-artifact@v4
      with:
        name: trained-model
        path: |
          models/*.pkl
          models/metrics.json
          mlruns/
        retention-days: 7
        if-no-files-found: warn
    
    # Output model artifacts for deployment job
    - name: Upload model artifacts for deployment
      uses: actions/upload-artifact@v4
      with:
        name: model-for-deployment
        path: |
          models/*.pkl
        retention-days: 1
        if-no-files-found: error

  # Job 3: Deploy to Staging
  # This job builds and deploys the inference API to staging environment
  deploy-staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: [lint-and-test, train-model]
    # Only deploy on push to main (not on pull requests)
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    environment:
      name: staging
      url: https://staging.example.com  # Update with your staging URL
    
    steps:
    # Checkout the code
    - name: Checkout code
      uses: actions/checkout@v4
    
    # Download model artifacts from training job
    - name: Download model artifacts
      uses: actions/download-artifact@v4
      with:
        name: model-for-deployment
        path: models/
    
    # Set up Docker Buildx for multi-platform builds
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
    
    # Log in to GitHub Container Registry
    # This allows us to push Docker images to ghcr.io
    - name: Log in to GitHub Container Registry
      uses: docker/login-action@v3
      with:
        registry: ghcr.io
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
    
    # Extract metadata for Docker tags
    # This creates tags like: ghcr.io/ereztdev/mlops:latest, ghcr.io/ereztdev/mlops:sha-abc123
    - name: Extract metadata
      id: meta
      uses: docker/metadata-action@v5
      with:
        images: ghcr.io/${{ github.repository }}
        tags: |
          type=ref,event=branch
          type=sha,prefix={{branch}}-
          type=raw,value=latest,enable={{is_default_branch}}
    
    # Build and push Docker image to GitHub Container Registry
    # This creates a containerized version of the inference API
    - name: Build and push Docker image
      uses: docker/build-push-action@v5
      with:
        context: .
        push: true
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max
    
    # Deploy to staging environment
    # This is a placeholder - in a real scenario, you would:
    # - Deploy to a cloud service (AWS, GCP, Azure)
    # - Update Kubernetes manifests
    # - Trigger a deployment script
    # For now, we'll just verify the image was built and pushed
    - name: Deploy to staging
      run: |
        echo "ðŸš€ Deployment to staging environment"
        echo "Image built and pushed: ${{ steps.meta.outputs.tags }}"
        echo "Staging environment configured"
        echo ""
        echo "In a production setup, this step would:"
        echo "  - Pull the image from registry"
        echo "  - Deploy to staging infrastructure"
        echo "  - Run health checks"
        echo "  - Update service endpoints"
        echo ""
        echo "For this learning project, the image is ready for deployment."
        echo "You can pull and run it with:"
        echo "  docker pull ${{ steps.meta.outputs.tags }}"
        echo "  docker run -p 8000:8000 ${{ steps.meta.outputs.tags }} python src/inference/app.py"

  # Job 4: Deploy to Production
  # This job deploys to production with manual approval gate
  # Requires human review before deploying to production
  deploy-production:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: [deploy-staging]
    # Only deploy on push to main (not on pull requests)
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    # Production environment requires manual approval
    # This creates a gate that must be approved in GitHub Actions UI
    environment:
      name: production
      url: https://production.example.com  # Update with your production URL
    
    steps:
    # Checkout the code
    - name: Checkout code
      uses: actions/checkout@v4
    
    # Download model artifacts from training job
    - name: Download model artifacts
      uses: actions/download-artifact@v4
      with:
        name: model-for-deployment
        path: models/
    
    # Set up Docker Buildx
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
    
    # Log in to GitHub Container Registry
    - name: Log in to GitHub Container Registry
      uses: docker/login-action@v3
      with:
        registry: ghcr.io
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
    
    # Extract metadata for production tags
    # Production uses 'production' tag in addition to version tags
    - name: Extract metadata
      id: meta
      uses: docker/metadata-action@v5
      with:
        images: ghcr.io/${{ github.repository }}
        tags: |
          type=raw,value=production
          type=raw,value=production-{{sha}}
          type=sha,prefix=prod-
    
    # Build and push production Docker image
    - name: Build and push production image
      uses: docker/build-push-action@v5
      with:
        context: .
        push: true
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max
    
    # Deploy to production environment
    # This is a placeholder - in a real scenario, you would:
    # - Deploy to production infrastructure (Kubernetes, cloud services)
    # - Run comprehensive health checks
    # - Update production service endpoints
    # - Monitor deployment metrics
    # - Set up rollback procedures
    - name: Deploy to production
      run: |
        echo "ðŸš€ Production Deployment"
        echo "================================"
        echo "Image built and pushed: ${{ steps.meta.outputs.tags }}"
        echo "Production environment configured"
        echo ""
        echo "âœ… Deployment approved and executed"
        echo ""
        echo "In a production setup, this step would:"
        echo "  - Deploy to production infrastructure"
        echo "  - Run health checks and smoke tests"
        echo "  - Update load balancer/service endpoints"
        echo "  - Monitor deployment metrics"
        echo "  - Set up automatic rollback on failure"
        echo ""
        echo "Production image available at:"
        echo "  docker pull ${{ steps.meta.outputs.tags }}"
        echo "  docker run -p 8000:8000 ${{ steps.meta.outputs.tags }} python src/inference/app.py"

